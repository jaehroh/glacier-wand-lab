{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 9: Agent Orchestration\n",
    "\n",
    "Orchestration is how you coordinate multiple capabilities (LLM calls, web fetching, document parsing, etc.) into coherent workflows.\n",
    "\n",
    "**This notebook covers:**\n",
    "1. Orchestration patterns (simple ‚Üí complex)\n",
    "2. Popular frameworks and when to use them\n",
    "3. Building a simple, understandable orchestrator from scratch\n",
    "4. A practical example: the cover letter agent\n",
    "\n",
    "**Philosophy:** Start simple. Add complexity only when you understand why you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Orchestration Patterns\n",
    "\n",
    "### Pattern 1: Sequential Pipeline (Simplest)\n",
    "\n",
    "```\n",
    "Input ‚Üí Step 1 ‚Üí Step 2 ‚Üí Step 3 ‚Üí Output\n",
    "```\n",
    "\n",
    "Just functions calling functions. No framework needed.\n",
    "\n",
    "**Pros:** Easy to understand, debug, and modify  \n",
    "**Cons:** No branching, no error recovery, no parallelism  \n",
    "**Use when:** Your workflow is linear and predictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Sequential Pipeline\n",
    "\n",
    "def step1_fetch(url: str) -> str:\n",
    "    \"\"\"Fetch content from URL.\"\"\"\n",
    "    # ... fetch logic ...\n",
    "    return \"fetched content\"\n",
    "\n",
    "def step2_analyze(content: str) -> dict:\n",
    "    \"\"\"Analyze content with LLM.\"\"\"\n",
    "    # ... LLM call ...\n",
    "    return {\"key_points\": [\"point1\", \"point2\"]}\n",
    "\n",
    "def step3_generate(analysis: dict) -> str:\n",
    "    \"\"\"Generate output document.\"\"\"\n",
    "    # ... generation logic ...\n",
    "    return \"final document\"\n",
    "\n",
    "# The \"orchestration\" is just function composition\n",
    "def run_pipeline(url: str) -> str:\n",
    "    content = step1_fetch(url)\n",
    "    analysis = step2_analyze(content)\n",
    "    result = step3_generate(analysis)\n",
    "    return result\n",
    "\n",
    "print(\"Pattern 1: Sequential pipeline - just functions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: State Machine\n",
    "\n",
    "```\n",
    "         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "         ‚îÇ  START   ‚îÇ\n",
    "         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚ñº\n",
    "         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ RESEARCH ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    "    ‚îÇ (enough)    (need more)\n",
    "    ‚ñº                    ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ ANALYZE  ‚îÇ       ‚îÇ  FETCH   ‚îÇ‚îÄ‚îÄ‚îê\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "     ‚îÇ                    ‚ñ≤      ‚îÇ\n",
    "     ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "     ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ GENERATE ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "     ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   DONE   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Pros:** Can loop, branch, retry  \n",
    "**Cons:** More complex, state management  \n",
    "**Use when:** Workflow has conditions, loops, or needs to recover from errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 2: State Machine\n",
    "\n",
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "class State(Enum):\n",
    "    START = auto()\n",
    "    RESEARCH = auto()\n",
    "    FETCH = auto()\n",
    "    ANALYZE = auto()\n",
    "    GENERATE = auto()\n",
    "    DONE = auto()\n",
    "    ERROR = auto()\n",
    "\n",
    "@dataclass\n",
    "class WorkflowContext:\n",
    "    \"\"\"Shared state across all steps.\"\"\"\n",
    "    state: State = State.START\n",
    "    input_data: dict = field(default_factory=dict)\n",
    "    research_results: list = field(default_factory=list)\n",
    "    analysis: dict = field(default_factory=dict)\n",
    "    output: str = \"\"\n",
    "    error: str = \"\"\n",
    "    iterations: int = 0\n",
    "    max_iterations: int = 5\n",
    "\n",
    "def run_state_machine(ctx: WorkflowContext) -> WorkflowContext:\n",
    "    \"\"\"Execute state machine until DONE or ERROR.\"\"\"\n",
    "    while ctx.state not in (State.DONE, State.ERROR):\n",
    "        ctx.iterations += 1\n",
    "        if ctx.iterations > ctx.max_iterations:\n",
    "            ctx.state = State.ERROR\n",
    "            ctx.error = \"Max iterations exceeded\"\n",
    "            break\n",
    "            \n",
    "        print(f\"  State: {ctx.state.name}\")\n",
    "        \n",
    "        if ctx.state == State.START:\n",
    "            ctx.state = State.RESEARCH\n",
    "            \n",
    "        elif ctx.state == State.RESEARCH:\n",
    "            # Decide if we need more research\n",
    "            if len(ctx.research_results) < 2:\n",
    "                ctx.state = State.FETCH\n",
    "            else:\n",
    "                ctx.state = State.ANALYZE\n",
    "                \n",
    "        elif ctx.state == State.FETCH:\n",
    "            # Simulate fetching\n",
    "            ctx.research_results.append(f\"Result {len(ctx.research_results) + 1}\")\n",
    "            ctx.state = State.RESEARCH  # Loop back\n",
    "            \n",
    "        elif ctx.state == State.ANALYZE:\n",
    "            ctx.analysis = {\"summary\": \"analyzed\"}\n",
    "            ctx.state = State.GENERATE\n",
    "            \n",
    "        elif ctx.state == State.GENERATE:\n",
    "            ctx.output = f\"Generated from {len(ctx.research_results)} sources\"\n",
    "            ctx.state = State.DONE\n",
    "    \n",
    "    return ctx\n",
    "\n",
    "# Test it\n",
    "ctx = WorkflowContext()\n",
    "result = run_state_machine(ctx)\n",
    "print(f\"\\nFinal state: {result.state.name}\")\n",
    "print(f\"Output: {result.output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: DAG (Directed Acyclic Graph)\n",
    "\n",
    "```\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚îÇ  Input  ‚îÇ\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚îÇ\n",
    "     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "     ‚ñº       ‚ñº       ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇFetch A ‚îÇ‚îÇFetch B ‚îÇ‚îÇFetch C ‚îÇ  ‚Üê Parallel!\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚îÇ         ‚îÇ         ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚ñº\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚îÇ  Merge   ‚îÇ\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚ñº\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚îÇ Generate ‚îÇ\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Pros:** Parallel execution, clear dependencies  \n",
    "**Cons:** More setup, need to handle concurrency  \n",
    "**Use when:** Steps can run in parallel, you need speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 4: ReAct (Reasoning + Acting)\n",
    "\n",
    "The LLM itself decides what to do next.\n",
    "\n",
    "```\n",
    "Loop:\n",
    "  1. LLM: \"I should search for company info\" (Thought)\n",
    "  2. System: Executes search tool (Action)\n",
    "  3. LLM sees results (Observation)\n",
    "  4. LLM: \"Now I have enough info to write\" (Thought)\n",
    "  5. System: Executes write tool (Action)\n",
    "  6. ...\n",
    "Until: LLM says \"DONE\"\n",
    "```\n",
    "\n",
    "**Pros:** Flexible, can handle unexpected situations  \n",
    "**Cons:** Unpredictable, can loop forever, expensive (many LLM calls)  \n",
    "**Use when:** Task is ambiguous, needs dynamic decision-making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Popular Frameworks\n",
    "\n",
    "| Framework | Best For | Complexity | Notes |\n",
    "|-----------|----------|------------|-------|\n",
    "| **LangChain** | General-purpose chains | Medium-High | Large ecosystem, can be overwhelming |\n",
    "| **LlamaIndex** | RAG / document Q&A | Medium | Great for search over documents |\n",
    "| **CrewAI** | Multi-agent collaboration | Medium | Agents with roles working together |\n",
    "| **AutoGen** | Conversational agents | Medium | Microsoft, good for chat-based agents |\n",
    "| **Haystack** | Search pipelines | Medium | Production-focused, well-documented |\n",
    "| **DSPy** | Prompt optimization | High | Automatically improves prompts |\n",
    "| **Prefect/Airflow** | Production workflows | High | Not AI-specific, but battle-tested |\n",
    "| **DIY** | Learning, simple tasks | Low | What we're building here! |\n",
    "\n",
    "### My Recommendation for Learning:\n",
    "\n",
    "1. **Start with DIY** (this notebook) ‚Äî understand the core concepts\n",
    "2. **Then try LangChain** ‚Äî it's the most popular, lots of tutorials\n",
    "3. **Graduate to specialized tools** as needed (CrewAI for multi-agent, LlamaIndex for RAG)\n",
    "\n",
    "### Why Not Start with a Framework?\n",
    "\n",
    "Frameworks hide complexity. That's great for productivity, bad for learning. When something breaks, you need to understand what's happening underneath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Building a Simple Orchestrator\n",
    "\n",
    "Let's build a minimal but useful orchestrator that:\n",
    "- Defines workflows as a series of steps\n",
    "- Passes context between steps\n",
    "- Handles errors gracefully\n",
    "- Logs what's happening\n",
    "- Supports human-in-the-loop checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Any, Optional\n",
    "from enum import Enum\n",
    "import traceback\n",
    "\n",
    "\n",
    "class StepStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    SKIPPED = \"skipped\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StepResult:\n",
    "    \"\"\"Result of executing a single step.\"\"\"\n",
    "    name: str\n",
    "    status: StepStatus\n",
    "    output: Any = None\n",
    "    error: Optional[str] = None\n",
    "    elapsed_time: float = 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Step:\n",
    "    \"\"\"A single step in a workflow.\"\"\"\n",
    "    name: str\n",
    "    func: Callable\n",
    "    description: str = \"\"\n",
    "    checkpoint: bool = False  # Pause for human approval?\n",
    "    skip_on_error: bool = False  # Continue if this step fails?\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WorkflowResult:\n",
    "    \"\"\"Result of running a complete workflow.\"\"\"\n",
    "    success: bool\n",
    "    steps: list[StepResult] = field(default_factory=list)\n",
    "    context: dict = field(default_factory=dict)\n",
    "    total_time: float = 0.0\n",
    "    \n",
    "    def summary(self) -> str:\n",
    "        lines = [f\"Workflow {'‚úÖ SUCCEEDED' if self.success else '‚ùå FAILED'}\"]\n",
    "        lines.append(f\"Total time: {self.total_time:.2f}s\")\n",
    "        lines.append(\"\\nSteps:\")\n",
    "        for step in self.steps:\n",
    "            icon = {\"completed\": \"‚úÖ\", \"failed\": \"‚ùå\", \"skipped\": \"‚è≠Ô∏è\"}.get(step.status.value, \"‚è≥\")\n",
    "            lines.append(f\"  {icon} {step.name} ({step.elapsed_time:.2f}s)\")\n",
    "            if step.error:\n",
    "                lines.append(f\"      Error: {step.error}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "class Orchestrator:\n",
    "    \"\"\"Simple workflow orchestrator.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"Workflow\", verbose: bool = True):\n",
    "        self.name = name\n",
    "        self.steps: list[Step] = []\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def add_step(\n",
    "        self,\n",
    "        name: str,\n",
    "        func: Callable,\n",
    "        description: str = \"\",\n",
    "        checkpoint: bool = False,\n",
    "        skip_on_error: bool = False,\n",
    "    ) -> \"Orchestrator\":\n",
    "        \"\"\"Add a step to the workflow. Returns self for chaining.\"\"\"\n",
    "        self.steps.append(Step(\n",
    "            name=name,\n",
    "            func=func,\n",
    "            description=description,\n",
    "            checkpoint=checkpoint,\n",
    "            skip_on_error=skip_on_error,\n",
    "        ))\n",
    "        return self\n",
    "    \n",
    "    def run(self, initial_context: dict = None) -> WorkflowResult:\n",
    "        \"\"\"Execute all steps in order.\"\"\"\n",
    "        context = initial_context or {}\n",
    "        results = []\n",
    "        start_time = time.time()\n",
    "        success = True\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üöÄ Starting: {self.name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "        \n",
    "        for step in self.steps:\n",
    "            step_start = time.time()\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"\\n‚ñ∂Ô∏è  Step: {step.name}\")\n",
    "                if step.description:\n",
    "                    print(f\"   {step.description}\")\n",
    "            \n",
    "            # Checkpoint: ask for human approval\n",
    "            if step.checkpoint:\n",
    "                if not self._checkpoint(step.name, context):\n",
    "                    results.append(StepResult(\n",
    "                        name=step.name,\n",
    "                        status=StepStatus.SKIPPED,\n",
    "                        elapsed_time=time.time() - step_start,\n",
    "                    ))\n",
    "                    continue\n",
    "            \n",
    "            try:\n",
    "                # Execute the step, passing context\n",
    "                output = step.func(context)\n",
    "                \n",
    "                # Step can return updated context or just a value\n",
    "                if isinstance(output, dict):\n",
    "                    context.update(output)\n",
    "                else:\n",
    "                    context[step.name] = output\n",
    "                \n",
    "                results.append(StepResult(\n",
    "                    name=step.name,\n",
    "                    status=StepStatus.COMPLETED,\n",
    "                    output=output,\n",
    "                    elapsed_time=time.time() - step_start,\n",
    "                ))\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"   ‚úÖ Completed in {time.time() - step_start:.2f}s\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                results.append(StepResult(\n",
    "                    name=step.name,\n",
    "                    status=StepStatus.FAILED,\n",
    "                    error=error_msg,\n",
    "                    elapsed_time=time.time() - step_start,\n",
    "                ))\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"   ‚ùå Failed: {error_msg}\")\n",
    "                \n",
    "                if not step.skip_on_error:\n",
    "                    success = False\n",
    "                    break\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"{'‚úÖ COMPLETED' if success else '‚ùå FAILED'} in {total_time:.2f}s\")\n",
    "            print(f\"{'='*60}\")\n",
    "        \n",
    "        return WorkflowResult(\n",
    "            success=success,\n",
    "            steps=results,\n",
    "            context=context,\n",
    "            total_time=total_time,\n",
    "        )\n",
    "    \n",
    "    def _checkpoint(self, step_name: str, context: dict) -> bool:\n",
    "        \"\"\"Pause for human approval. Returns True to continue, False to skip.\"\"\"\n",
    "        print(f\"\\n‚è∏Ô∏è  CHECKPOINT before '{step_name}'\")\n",
    "        print(f\"   Current context keys: {list(context.keys())}\")\n",
    "        response = input(\"   Continue? [Y/n/show]: \").strip().lower()\n",
    "        \n",
    "        if response == 'show':\n",
    "            import json\n",
    "            # Show context (truncated)\n",
    "            for k, v in context.items():\n",
    "                v_str = str(v)[:200]\n",
    "                print(f\"   {k}: {v_str}\")\n",
    "            return self._checkpoint(step_name, context)  # Ask again\n",
    "        \n",
    "        return response != 'n'\n",
    "\n",
    "\n",
    "print(\"‚úÖ Orchestrator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some simple step functions\n",
    "def fetch_data(ctx):\n",
    "    \"\"\"Simulate fetching data.\"\"\"\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    return {\"raw_data\": \"This is the fetched content about AI and machine learning.\"}\n",
    "\n",
    "def analyze_data(ctx):\n",
    "    \"\"\"Analyze the fetched data.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    data = ctx.get(\"raw_data\", \"\")\n",
    "    return {\"word_count\": len(data.split()), \"has_ai\": \"AI\" in data}\n",
    "\n",
    "def generate_summary(ctx):\n",
    "    \"\"\"Generate a summary.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return {\"summary\": f\"Document has {ctx['word_count']} words. AI mentioned: {ctx['has_ai']}\"}\n",
    "\n",
    "# Build and run the workflow\n",
    "workflow = Orchestrator(\"Simple Analysis Pipeline\")\n",
    "workflow.add_step(\"fetch\", fetch_data, \"Fetch content from source\")\n",
    "workflow.add_step(\"analyze\", analyze_data, \"Analyze the content\")\n",
    "workflow.add_step(\"summarize\", generate_summary, \"Generate summary\")\n",
    "\n",
    "result = workflow.run()\n",
    "print(\"\\n\" + result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same workflow but with a checkpoint before generation\n",
    "workflow_with_checkpoint = Orchestrator(\"Pipeline with Review\")\n",
    "workflow_with_checkpoint.add_step(\"fetch\", fetch_data, \"Fetch content\")\n",
    "workflow_with_checkpoint.add_step(\"analyze\", analyze_data, \"Analyze content\")\n",
    "workflow_with_checkpoint.add_step(\n",
    "    \"summarize\", \n",
    "    generate_summary, \n",
    "    \"Generate summary\",\n",
    "    checkpoint=True  # Will pause here!\n",
    ")\n",
    "\n",
    "result = workflow_with_checkpoint.run()\n",
    "print(\"\\nFinal summary:\", result.context.get(\"summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Cover Letter Agent (Putting It Together)\n",
    "\n",
    "Let's build the cover letter workflow using real modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# We'll simulate some modules for now\n",
    "# In practice, you'd import from src/\n",
    "\n",
    "def step_parse_resume(ctx):\n",
    "    \"\"\"Parse resume and extract key information.\"\"\"\n",
    "    # In practice: use document parser module\n",
    "    resume_text = ctx.get(\"resume_text\", \"\")\n",
    "    \n",
    "    # Use LLM to extract structured info\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"Extract key information from this resume. Return as a structured summary:\n",
    "- Name\n",
    "- Current/Recent Role\n",
    "- Key Skills (top 5)\n",
    "- Years of Experience\n",
    "- Notable Achievements (top 3)\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Structured Summary:\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return {\"resume_summary\": response['message']['content']}\n",
    "\n",
    "\n",
    "def step_parse_job(ctx):\n",
    "    \"\"\"Parse job posting and extract requirements.\"\"\"\n",
    "    job_text = ctx.get(\"job_text\", \"\")\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"Extract key information from this job posting:\n",
    "- Job Title\n",
    "- Company Name\n",
    "- Required Skills\n",
    "- Nice-to-have Skills\n",
    "- Key Responsibilities\n",
    "- Company Culture hints\n",
    "\n",
    "Job Posting:\n",
    "{job_text}\n",
    "\n",
    "Structured Summary:\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return {\"job_summary\": response['message']['content']}\n",
    "\n",
    "\n",
    "def step_match_analysis(ctx):\n",
    "    \"\"\"Analyze how well resume matches job.\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"Compare this resume to this job posting.\n",
    "\n",
    "Resume Summary:\n",
    "{ctx['resume_summary']}\n",
    "\n",
    "Job Summary:\n",
    "{ctx['job_summary']}\n",
    "\n",
    "Provide:\n",
    "1. Top 3 strengths that match the job\n",
    "2. Top 2 potential gaps to address\n",
    "3. Unique value proposition (what makes this candidate stand out)\n",
    "\n",
    "Analysis:\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return {\"match_analysis\": response['message']['content']}\n",
    "\n",
    "\n",
    "def step_generate_letter(ctx):\n",
    "    \"\"\"Generate the cover letter.\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"Write a professional cover letter based on this analysis.\n",
    "\n",
    "Resume Summary:\n",
    "{ctx['resume_summary']}\n",
    "\n",
    "Job Summary:\n",
    "{ctx['job_summary']}\n",
    "\n",
    "Match Analysis:\n",
    "{ctx['match_analysis']}\n",
    "\n",
    "Guidelines:\n",
    "- Professional but personable tone\n",
    "- Lead with the strongest match\n",
    "- Address one gap positively (as growth opportunity)\n",
    "- Show enthusiasm for the specific company\n",
    "- Keep to 3-4 paragraphs\n",
    "\n",
    "Cover Letter:\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return {\"cover_letter\": response['message']['content']}\n",
    "\n",
    "\n",
    "print(\"‚úÖ Cover letter steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the cover letter workflow\n",
    "cover_letter_workflow = Orchestrator(\"Cover Letter Generator\")\n",
    "\n",
    "cover_letter_workflow.add_step(\n",
    "    \"parse_resume\",\n",
    "    step_parse_resume,\n",
    "    \"Extract key info from resume\"\n",
    ")\n",
    "\n",
    "cover_letter_workflow.add_step(\n",
    "    \"parse_job\",\n",
    "    step_parse_job,\n",
    "    \"Extract requirements from job posting\"\n",
    ")\n",
    "\n",
    "cover_letter_workflow.add_step(\n",
    "    \"match_analysis\",\n",
    "    step_match_analysis,\n",
    "    \"Analyze resume-job fit\",\n",
    "    checkpoint=True  # Review analysis before generating\n",
    ")\n",
    "\n",
    "cover_letter_workflow.add_step(\n",
    "    \"generate_letter\",\n",
    "    step_generate_letter,\n",
    "    \"Generate tailored cover letter\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Workflow built with\", len(cover_letter_workflow.steps), \"steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample data\n",
    "sample_resume = \"\"\"\n",
    "Jane Smith\n",
    "Senior Software Engineer\n",
    "\n",
    "Experience:\n",
    "- 7 years building web applications\n",
    "- Led team of 5 engineers at TechCorp\n",
    "- Architected microservices handling 1M requests/day\n",
    "\n",
    "Skills: Python, JavaScript, AWS, Docker, PostgreSQL, React\n",
    "\n",
    "Achievements:\n",
    "- Reduced deployment time by 80% with CI/CD pipeline\n",
    "- Mentored 3 junior developers to senior level\n",
    "- Open source contributor to FastAPI\n",
    "\"\"\"\n",
    "\n",
    "sample_job = \"\"\"\n",
    "Staff Engineer - Platform Team\n",
    "Acme Inc.\n",
    "\n",
    "We're looking for an experienced engineer to help build our next-generation platform.\n",
    "\n",
    "Requirements:\n",
    "- 5+ years of backend development\n",
    "- Experience with distributed systems\n",
    "- Strong Python or Go skills\n",
    "- Kubernetes experience preferred\n",
    "\n",
    "Nice to have:\n",
    "- ML/AI experience\n",
    "- Technical leadership\n",
    "\n",
    "About us: We're a fast-growing startup building tools for developers.\n",
    "We value collaboration, learning, and shipping quality software.\n",
    "\"\"\"\n",
    "\n",
    "# Run the workflow!\n",
    "result = cover_letter_workflow.run({\n",
    "    \"resume_text\": sample_resume,\n",
    "    \"job_text\": sample_job,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated cover letter\n",
    "if result.success:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATED COVER LETTER\")\n",
    "    print(\"=\"*60)\n",
    "    print(result.context.get(\"cover_letter\", \"No letter generated\"))\n",
    "else:\n",
    "    print(\"Workflow failed:\")\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Next Steps\n",
    "\n",
    "### Extend the Orchestrator\n",
    "- Add **parallel execution** for independent steps\n",
    "- Add **retry logic** for flaky steps\n",
    "- Add **logging** to file for debugging\n",
    "- Add **persistence** to resume failed workflows\n",
    "\n",
    "### Try a Framework\n",
    "Now that you understand the concepts, try:\n",
    "```bash\n",
    "pip install langchain  # Most popular\n",
    "pip install crewai     # Multi-agent\n",
    "```\n",
    "\n",
    "### Build More Workflows\n",
    "- Research report generator\n",
    "- Code review assistant\n",
    "- Meeting notes summarizer\n",
    "\n",
    "The orchestrator pattern works for all of these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export as Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_code = '''\n",
    "\"\"\"Simple Workflow Orchestrator.\"\"\"\n",
    "\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Any, Optional\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class StepStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    SKIPPED = \"skipped\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StepResult:\n",
    "    name: str\n",
    "    status: StepStatus\n",
    "    output: Any = None\n",
    "    error: Optional[str] = None\n",
    "    elapsed_time: float = 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Step:\n",
    "    name: str\n",
    "    func: Callable\n",
    "    description: str = \"\"\n",
    "    checkpoint: bool = False\n",
    "    skip_on_error: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WorkflowResult:\n",
    "    success: bool\n",
    "    steps: list[StepResult] = field(default_factory=list)\n",
    "    context: dict = field(default_factory=dict)\n",
    "    total_time: float = 0.0\n",
    "    \n",
    "    def summary(self) -> str:\n",
    "        lines = [f\"Workflow {\\\"‚úÖ SUCCEEDED\\\" if self.success else \\\"‚ùå FAILED\\\"}\"]\n",
    "        lines.append(f\"Total time: {self.total_time:.2f}s\")\n",
    "        for step in self.steps:\n",
    "            icon = {\"completed\": \"‚úÖ\", \"failed\": \"‚ùå\", \"skipped\": \"‚è≠Ô∏è\"}.get(step.status.value, \"‚è≥\")\n",
    "            lines.append(f\"  {icon} {step.name} ({step.elapsed_time:.2f}s)\")\n",
    "        return \"\\\\n\".join(lines)\n",
    "\n",
    "\n",
    "class Orchestrator:\n",
    "    def __init__(self, name: str = \"Workflow\", verbose: bool = True):\n",
    "        self.name = name\n",
    "        self.steps: list[Step] = []\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def add_step(self, name: str, func: Callable, description: str = \"\",\n",
    "                 checkpoint: bool = False, skip_on_error: bool = False) -> \"Orchestrator\":\n",
    "        self.steps.append(Step(name, func, description, checkpoint, skip_on_error))\n",
    "        return self\n",
    "    \n",
    "    def run(self, initial_context: dict = None) -> WorkflowResult:\n",
    "        context = initial_context or {}\n",
    "        results = []\n",
    "        start_time = time.time()\n",
    "        success = True\n",
    "        \n",
    "        for step in self.steps:\n",
    "            step_start = time.time()\n",
    "            if self.verbose:\n",
    "                print(f\"‚ñ∂Ô∏è  {step.name}\")\n",
    "            \n",
    "            try:\n",
    "                output = step.func(context)\n",
    "                if isinstance(output, dict):\n",
    "                    context.update(output)\n",
    "                else:\n",
    "                    context[step.name] = output\n",
    "                results.append(StepResult(step.name, StepStatus.COMPLETED, output, \n",
    "                                         elapsed_time=time.time() - step_start))\n",
    "            except Exception as e:\n",
    "                results.append(StepResult(step.name, StepStatus.FAILED, error=str(e),\n",
    "                                         elapsed_time=time.time() - step_start))\n",
    "                if not step.skip_on_error:\n",
    "                    success = False\n",
    "                    break\n",
    "        \n",
    "        return WorkflowResult(success, results, context, time.time() - start_time)\n",
    "'''\n",
    "\n",
    "with open('/home/developer/projects/sandbox-experiments/src/orchestrator.py', 'w') as f:\n",
    "    f.write(module_code.strip())\n",
    "\n",
    "print(\"‚úÖ Saved to src/orchestrator.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
